1
00:00:00,068 --> 00:00:07,305
[MUSIC]

2
00:00:07,305 --> 00:00:08,770
Welcome to this lecture.

3
00:00:08,770 --> 00:00:13,770
This short lecture presents the so
called refined process mining framework.

4
00:00:13,770 --> 00:00:16,690
This framework aims to
provide an overview of

5
00:00:16,690 --> 00:00:18,829
the different process mining activities.

6
00:00:20,450 --> 00:00:23,620
This is a diagram that we have
seen several times before.

7
00:00:23,620 --> 00:00:27,540
It is explaining the role of discovery,
conformance, and enhancement.

8
00:00:28,730 --> 00:00:33,920
Today we will refine this framework
into a much more detailed framework.

9
00:00:33,920 --> 00:00:38,490
Identifying ten different
process mining activities.

10
00:00:38,490 --> 00:00:45,110
And, we will explain this more
complicated framework, step-by-step.

11
00:00:45,110 --> 00:00:48,160
In the earlier lectures,
we focused on process discovery.

12
00:00:49,220 --> 00:00:51,450
Only looking at control flow.

13
00:00:51,450 --> 00:00:54,020
Then we looked at conformance checking.

14
00:00:54,020 --> 00:00:56,980
And in the last couple of lectures
we have been extending this in

15
00:00:56,980 --> 00:00:59,050
all kinds of directions.

16
00:00:59,050 --> 00:01:03,980
We have been incorporating role
information about a resource involved in

17
00:01:03,980 --> 00:01:05,370
a process.

18
00:01:05,370 --> 00:01:07,070
We looked at decision point mining.

19
00:01:07,070 --> 00:01:08,970
We looked at bottlenecks.

20
00:01:08,970 --> 00:01:11,440
But this is just the tip of the iceberg.

21
00:01:11,440 --> 00:01:15,440
There are many more process mining
techniques that one can use.

22
00:01:15,440 --> 00:01:19,370
And there are much more
questions that one could ask.

23
00:01:19,370 --> 00:01:22,520
For example, one can ask
questions related to performance.

24
00:01:22,520 --> 00:01:25,720
If you are dealing with
terabytes of event data,

25
00:01:25,720 --> 00:01:28,700
you need to distribute your
process mining activities.

26
00:01:30,370 --> 00:01:34,150
Today's framework will
not focus in things like.

27
00:01:34,150 --> 00:01:35,910
Distributed process mining.

28
00:01:35,910 --> 00:01:40,630
But will look at the typical
activities that you may want to

29
00:01:40,630 --> 00:01:43,620
do in the context of
a process mining project.

30
00:01:45,320 --> 00:01:49,680
And for that we detail this
refined process mining framework.

31
00:01:52,180 --> 00:01:57,130
Let's start with the top
of the refined framework.

32
00:01:57,130 --> 00:01:59,580
You can see the word provenance here.

33
00:01:59,580 --> 00:02:03,860
The word provenance refers to
the fact that event data that we

34
00:02:03,860 --> 00:02:06,280
are collecting should be faithful.

35
00:02:06,280 --> 00:02:09,230
It should describe what
has really happened.

36
00:02:09,230 --> 00:02:12,990
Once we collect event data,
it should be safe.

37
00:02:12,990 --> 00:02:16,040
Data should not just disappear,
preferably,

38
00:02:16,040 --> 00:02:17,980
also not disappear selectively.

39
00:02:19,010 --> 00:02:22,850
We should always be able to
reconstruct history based on

40
00:02:22,850 --> 00:02:24,870
the event data that we have.

41
00:02:24,870 --> 00:02:26,580
So this is something
that is very important.

42
00:02:27,780 --> 00:02:31,060
So suppose now that we
have the event data,

43
00:02:31,060 --> 00:02:33,890
then we can partition the event data.

44
00:02:33,890 --> 00:02:38,140
Into pre mortem and
post mortem event data.

45
00:02:38,140 --> 00:02:38,870
What does it mean?

46
00:02:40,210 --> 00:02:42,630
If you look at post mortem event data,

47
00:02:42,630 --> 00:02:49,300
we look at event data that refers to cases
that have already completely finished.

48
00:02:49,300 --> 00:02:53,920
So these were cases that
were handled in the past.

49
00:02:53,920 --> 00:02:55,740
We can no longer influence them.

50
00:02:57,200 --> 00:02:59,980
If you look at pre mortem event data,

51
00:02:59,980 --> 00:03:04,190
we refer to cases that are still running,
that are still alive.

52
00:03:04,190 --> 00:03:10,650
And, if we look at these cases,
we may still want to influence them.

53
00:03:10,650 --> 00:03:15,680
For example if we see a case and we can
we know that the case is running late.

54
00:03:15,680 --> 00:03:20,660
We could for example try to involve
additional resources to make

55
00:03:20,660 --> 00:03:23,430
sure that the case is handled in time.

56
00:03:23,430 --> 00:03:28,260
So pre mortem event data refers to
cases that can still be influenced.

57
00:03:29,720 --> 00:03:34,150
It's important to make this
distinction for

58
00:03:34,150 --> 00:03:35,290
the rest of the framework.

59
00:03:37,170 --> 00:03:38,930
Let's take a look at some examples.

60
00:03:38,930 --> 00:03:45,260
So, here you can see three different
situations, students studying.

61
00:03:45,260 --> 00:03:46,830
We can look at the sales process,

62
00:03:46,830 --> 00:03:50,440
we can look at the hospital
with patient related data.

63
00:03:50,440 --> 00:03:54,000
And if we look at post
mortem like questions,

64
00:03:54,000 --> 00:03:55,930
we are interested in bottlenecks.

65
00:03:55,930 --> 00:04:00,650
We are interested in seeing how we
could improve the process, not for

66
00:04:00,650 --> 00:04:04,128
the case that is running now,
but for the process in general.

67
00:04:04,128 --> 00:04:07,910
That's post-mortem data.

68
00:04:07,910 --> 00:04:11,880
If we look at pre-mortem data,
we are particularly interested in

69
00:04:11,880 --> 00:04:16,040
the cases that are running now,
and that can still be influenced.

70
00:04:16,040 --> 00:04:20,600
So for example, if we see that a
particular student is likely to drop out,

71
00:04:20,600 --> 00:04:22,890
we may still want to take some action.

72
00:04:22,890 --> 00:04:27,470
Or if we see that students are not
engaged enough in a particular course,

73
00:04:27,470 --> 00:04:28,480
we can take action.

74
00:04:30,380 --> 00:04:34,847
We can also take action, for example,
if we look at a hospital and

75
00:04:34,847 --> 00:04:38,921
we see certain non-conformance
of a particular patient.

76
00:04:38,921 --> 00:04:45,260
That we want to take action to make
sure that no bigger problems will occur.

77
00:04:46,350 --> 00:04:50,529
So pre mortem data refers to cases
that we can still influence.

78
00:04:52,720 --> 00:04:58,520
At the bottom of the diagram of
the reference model we look at the models.

79
00:04:58,520 --> 00:05:02,770
And the models may cover
multiple perspectives.

80
00:05:02,770 --> 00:05:05,910
They typically always
cover control flow.

81
00:05:05,910 --> 00:05:09,850
But with the control flow
backbone we may add data and

82
00:05:09,850 --> 00:05:13,940
rules, information about resources,
about time, costs, etc.

83
00:05:15,910 --> 00:05:20,030
At the bottom of the diagram you can also
see that we distinguish between the de

84
00:05:20,030 --> 00:05:23,160
jure models and the de facto models.

85
00:05:23,160 --> 00:05:25,192
Let's take a look at what that means.

86
00:05:25,192 --> 00:05:28,737
The de facto model is descriptive,

87
00:05:28,737 --> 00:05:34,800
the de facto model tries to
describe reality as it is.

88
00:05:34,800 --> 00:05:39,200
It is not intended to
influence behavior or

89
00:05:39,200 --> 00:05:43,360
to guide behavior but
just to describe what is happening.

90
00:05:43,360 --> 00:05:47,570
When we do process discovery
we discover de facto models.

91
00:05:49,100 --> 00:05:50,920
But we also have de jure models.

92
00:05:50,920 --> 00:05:53,860
These models are typically normative.

93
00:05:53,860 --> 00:05:57,730
They specify how things should be done or
handled.

94
00:05:58,730 --> 00:06:01,900
For example if one is
using a workflow system or

95
00:06:01,900 --> 00:06:05,300
a BPM system,
one is using normative models.

96
00:06:05,300 --> 00:06:09,950
These models are driving the system to
force people to work in a particular way.

97
00:06:11,240 --> 00:06:15,540
If we have models just on paper
they can still be normative.

98
00:06:15,540 --> 00:06:19,630
However if they are not enforced
by a system people can choose to

99
00:06:19,630 --> 00:06:22,310
deviate from them if they want.

100
00:06:22,310 --> 00:06:25,570
So we have de facto and de jure models and

101
00:06:25,570 --> 00:06:30,250
it's very important to see that our
roles may be completely different.

102
00:06:31,560 --> 00:06:35,980
Based on the difference between
de jure and de facto models and

103
00:06:35,980 --> 00:06:42,060
pre mortem and post mortem data
we can create this framework.

104
00:06:42,060 --> 00:06:47,610
And this framework identifies ten
different activities by no means.

105
00:06:47,610 --> 00:06:49,600
It is intended to be complete but

106
00:06:49,600 --> 00:06:54,080
it gives a good feeling of the broadness
of the process mining spectrum.

107
00:06:56,510 --> 00:06:59,900
Let's take a look at these
ten different activities.

108
00:06:59,900 --> 00:07:04,310
The first group of activities
looks at process models as maps.

109
00:07:04,310 --> 00:07:09,220
So the most typical example is discovery.

110
00:07:09,220 --> 00:07:13,250
Control flow discovery or
discovery of other perspectives.

111
00:07:14,270 --> 00:07:19,880
This is learning the model of
the process as it is really happening.

112
00:07:20,880 --> 00:07:25,230
We can also combine an existing
model with event data, and

113
00:07:25,230 --> 00:07:28,220
then extend or repair the model.

114
00:07:29,270 --> 00:07:32,520
And models can also serve
a purpose just by themselves,

115
00:07:32,520 --> 00:07:34,370
not directly connected to event data.

116
00:07:34,370 --> 00:07:38,202
And so for example, the model that
was discovered at some point in time.

117
00:07:38,202 --> 00:07:39,122
Can be used for

118
00:07:39,122 --> 00:07:43,660
diagnosis purposes much later without
really looking at event data.

119
00:07:46,400 --> 00:07:50,060
The activities in the middle,
they refer to auditing.

120
00:07:50,060 --> 00:07:54,030
So here we are confronting
model with reality.

121
00:07:54,030 --> 00:07:58,250
And we distinguish four
different activities.

122
00:07:58,250 --> 00:07:59,960
The first activity is detect.

123
00:08:01,310 --> 00:08:04,220
It is using pre mortem data.

124
00:08:04,220 --> 00:08:07,560
So data related to cases
that are still running.

125
00:08:07,560 --> 00:08:10,310
And they are compared
with the de jure models.

126
00:08:10,310 --> 00:08:14,820
And each time there is a deviation
an alert is generated.

127
00:08:15,940 --> 00:08:19,700
Note that we are now looking at
the online setting where want to

128
00:08:19,700 --> 00:08:22,780
generate alert the moment
that thy take place.

129
00:08:24,430 --> 00:08:29,140
A more common situation that we have
discussed many times in the past.

130
00:08:29,140 --> 00:08:32,470
It's conformance checking,
simply called check here.

131
00:08:32,470 --> 00:08:37,450
This is done in an offline setting,
so we look at the past, and

132
00:08:37,450 --> 00:08:40,500
we compare event data
with the process model.

133
00:08:43,510 --> 00:08:48,870
Detect and check, they have in common that
we compare event data with the model.

134
00:08:48,870 --> 00:08:51,960
We can also compare two models.

135
00:08:51,960 --> 00:08:56,860
For example, when we were discussing about
foot prints, we provided metrics for

136
00:08:56,860 --> 00:08:58,470
comparing two different models.

137
00:09:00,890 --> 00:09:04,630
This way we can again compare
the de jure with de facto model.

138
00:09:04,630 --> 00:09:08,050
Or we can compare different
variants of the same process.

139
00:09:08,050 --> 00:09:09,370
At the level of a model.

140
00:09:11,430 --> 00:09:15,530
Last but not least, 
we have the activity promote.

141
00:09:15,530 --> 00:09:19,170
It means that we have elements of a de

142
00:09:19,170 --> 00:09:22,810
facto model that we want to
transfer to a de jure model.

143
00:09:23,850 --> 00:09:26,190
So if you look at model repair,

144
00:09:26,190 --> 00:09:30,440
that would be something, typical activity
that you could see in this context.

145
00:09:33,090 --> 00:09:38,320
The last category of activities
are related to navigation, supporting, and

146
00:09:38,320 --> 00:09:39,960
guiding process execution.

147
00:09:41,130 --> 00:09:44,610
First of all,
using a combination of event data, and

148
00:09:44,610 --> 00:09:48,330
models, we may explore
the process at run time.

149
00:09:49,450 --> 00:09:51,840
It's just like a query language.

150
00:09:51,840 --> 00:09:55,440
We can try to understand what is
happening now and should we do something.

151
00:09:57,410 --> 00:10:00,180
Then there is the notion of prediction.

152
00:10:00,180 --> 00:10:03,330
If you have learned the model
based on historic information.

153
00:10:04,450 --> 00:10:07,380
And you combine that with pre mortem data,

154
00:10:07,380 --> 00:10:11,879
data about running cases in the current
state, you can make predictions.

155
00:10:13,080 --> 00:10:18,180
And if you can make predictions you
can also recommend certain actions.

156
00:10:18,180 --> 00:10:22,760
And so
using information from the past you can

157
00:10:22,760 --> 00:10:28,070
recommend a particular activity,
or a particular resource.

158
00:10:28,070 --> 00:10:30,470
To execute the next activity.

159
00:10:32,560 --> 00:10:36,320
So, these examples,
these ten different activities showed that

160
00:10:36,320 --> 00:10:39,770
the process mining spectrum
is actually quite broad.

161
00:10:39,770 --> 00:10:42,160
Much broader than just process discovery.

162
00:10:44,720 --> 00:10:46,950
We are now in Chapter nine.

163
00:10:46,950 --> 00:10:50,340
Operational support so
the refined process mining

164
00:10:50,340 --> 00:10:55,540
framework was an introduction to the more
online setting of process mining.

165
00:10:55,540 --> 00:10:58,250
And the next lecture we'll
talk about this in detail.

166
00:10:59,390 --> 00:11:02,711
Thank you for watching and
hope to see you soon.

167
00:11:02,711 --> 00:11:12,711
[MUSIC]

