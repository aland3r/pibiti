[MUSIC]
Glad to see you again for
this third lecture of the course on
Process Mining, Data Science in Action.
Today, we will see how process
mining relates to data mining.
Process mining,
as I explained in the last lecture,
is the missing link between
model based analysis,
process model based analysis, and
data oriented analysis like data mining.
With the goal to answer
performance oriented questions and
compliance oriented questions.
So one can think of process
mining as super glue.
It's the glue between data and processes.
It's the glue between business people and
IT people.
It's the glue between
business intelligence and
business process management.
It's the glue between performance and
compliance.
And you can do this at runtime,
and at design time.
So it's connecting many different things,
and that makes it so incredibly valuable.
This diagram gives a kind of
overview showing that process
mining is this world, this discipline
connecting business process
management to classical data
analytics like data mining.
And, as we have seen in the last lecture,
process mining consists of different
types of mining, and here you can see
process discovery and conformance checking.
Later we will also look
at predictive analytics.
How you can use process mining to
predict things about the future.
If you see this diagram,
you may ask yourself the question,
how about BI, business intelligence?
Well if you look at the classical
BI tools, they tend to show
only spreadsheets, meters, graphs,
they try to capture reality in a set
of numbers, and that is not sufficient.
This is illustrated by
Anscombe's Quartet that's the four
diagrams that you see here.
And let me explain what we are seeing.
We are seeing four different data sets,
each consisting of 11 elements.
They look very different, but
if you look at their statistical
properties, they are almost the same.
So if we look at the mean x
coordinate of these 11 elements in
each of the four cases the mean is nine,
the variance is 11.
If we look at the y coordinate,
we also can see that all of these
four diagrams are exactly the same.
Even when we apply linear regression,
all of these four data sets,
yield exactly the same result.
So, this is illustrating,
if a BI tool is just showing numbers,
that is often not sufficient.
You have to look behind the numbers,
because things can be very different.
One can think of process mining
as finding desire lines.
Here you can see a photo that I took at
a campus of Tsinghua University in Beijing,
and here you see one of my colleagues
there walking over a desire line.
So this is a trail in a grassy area
that is showing what people really do.
So, the trail can be seen
as the event data, and
the sign saying that you should not
walk there, that you should use the
official route can be
seen as the process model.
So this is an illustration of
what process mining tries to do.
You try to uncover the desire lines,
what do people really do.
And, you can find very surprising things.
So for
example if you look at this desire line,
it is clearly showing that people
do not follow the process model.
The, the gates that you see here is aimed
of keeping cyclists out of this park.
But what you can see is that
the desire line is showing that people
do not follow the things
that they should do here.
So the gate does not work
as it is supposed to work.
So using process mining and
conformance checking, you can use and
show these types of things.
Now it's time for a demo that we can
see process discovery in action.
Let's take a look at an example
of process mining in action.
What I see here is that I load an event
log into the process mining tool ProM, and
I apply one of the standard
process mining algorithms in ProM.
I'm applying the so-called fuzzy miner.
And based on raw event data,
I automatically learn a process model,
as you can see here, and
it goes incredibly fast.
We can zoom in to the model.
We can look at the different activities.
And the arcs connecting
the activities are showing how
cases are flowing through
this process model.
We can zoom in and zoom out just
like when you use Google Maps.
So now I look at the same process model
at the higher level of abstraction.
We see fewer activities because we
only show the frequent activities at
the highest level.
We can also replay
reality on such a model.
So I'm now loading both
the model that I discovered and
the event log, and I'm applying
a so-called replay algorithm on it.
So what you now see is not a simulation.
What you're seeing is that we are
replaying reality on top of this model.
So all the white dots,
refer to real cases.
What we can see,
you can see the numbers next to the cases,
we can follow individual cases.
We can see all the events.
We can see congestion in the process.
We can see frequent paths and
infrequent paths.
And I think this is a very nice
illustration that without any modeling,
you can see what is happening in reality,
through process mining.
So let's take a look at another metaphor
showing what process
discovery is all about.
You can compare process discovery to
learning a language based on examples.
So here you say see a mother, and the
mother is saying sentences to the child.
So the mother is saying a b c, and
the child is trying to learn the language.
So if the mother would always
say just the words a b and c.
The child would think okay, this language
is a b c and that's all that exists.
Then if the mother would say an a b d,
the child will think oh,
at the end there is apparently
a choice between c and d.
So, this child is very smart,
thinking already in terms
already of regular expressions.
So, this is the model of
the language that the child infers.
Then mother says another sentence, a d.
So, now the child has to think
what could this language be about?
So it's apparently a and d, or
it is a b and then followed by c or d.
Now the mother says, a b b c.
Another example,
trace that we can observe.
And now the child makes
a jump in learning, and
infers that apparently the number of b's
is variable, it can be zero or more etc.
And so the mother says more words and
if it fits into the language,
then the child has a good
understanding of that language.
So, in this example we can see a sentence
and compare that to a trace in
an event log, and we can think of
the language as a process model.
So, this is the relationship between
understanding a language based on
examples from learning a process model
just by looking at the examples.
What we saw in the last
lecture is that next to
process discovery we also
have conformance checking.
In that case, you want to see how does
reality deviate from the modeled process.
You can compare that to spell checking.
So the spell checker has a model of the
language, and you type a piece of text and
then it is checked,
whether that piece of text
fits the language,
as it has been formalized.
This can be compared to the typical
diagnostics that you get when
you do conformance checking in
the area of process mining.
So you see the activities
that have happened, but
that should not happen,
or the other way around.
Or you will see activities that were
executed too late, or too early, or
by the wrong person.
This can all be compared
by spell checking.
So in the remainder of this week,
we will focus on the topic of Data Mining.
As I have explained, also in the previous
lecture, process mining is very different
from the classical data mining techniques,
but there are many relationships.
So in this course, you will also get a
basic understanding of what process mining
is all about and
of course also data mining.
So, the growth of the digital universe
is driving the fact that many people
are using data mining techniques.
Initially the term data mining
had a very negative connotation.
People talked about it as data snooping,
fishing, etc.
Statisticians did not consider
it the proper way to do, but
this is now a very mature discipline
driven by these huge amounts of data.
But data mining is data-centric and
not process-centric.
So let us take a look at
some typical data sets, and
then try to think what data mining can do.
So, what you see here, is a data
set of more than 800 persons that
have died at a particular age while
having a particular weight and
it was recorded whether they
were drinking or smoking.
So for example, the first row corresponds
to a person that died at the age of 44
while being a drinker and a smoker and
having a weight of 120 kilos.
So this is an example of a data set.
And the types of questions that you can
ask about such a data set are things like,
do people that smoke also drink.
When do people get old.
What kind of properties
do they have in common?
The people typically that, that get old.
So what is the impact
of a certain lifestyle,
on the life
expectancy of a person?
So this is one data set and
typical data mining questions.
This is another data set.
And every row now corresponds
to a student at the university.
And what we see here are different
columns referring to different courses.
We can see the marks that people got for
each of these courses.
We can see the duration of
their studies in months, and
we can see whether they passed,
failed, or graduated cum laude.
So again, if we have such a data set
we can ask all kinds of questions.
So, are there certain courses that
are typically taken together, or
do marks of different
courses highly correlate?
If people fail,
what are the typical courses that
are leading to such a failure.
When and why do people drop out?
It's a different type of analysis that
you can do based on such a data set.
But we can look at all
kinds of other data sets.
So here you can see the
different orders in a cafe.
So every row refers to an order,
so if you look at the first row,
you see a person that has ordered
a cappuccino and a muffin.
So every row corresponds to an order, and
again you can try to learn
all kinds of things.
So, you can try to find out
which are the products which
are typically purchased together.
You could try to find out
are there characteristic groups of
customers that typically
consume similar things.
And all of this can be used
to try to promote sales.
So these three data sets give all kinds
of examples for data mining problems.
So if you look at the raw data that
we get in each of these examples.
Is we, if I get a table, every row in
the table corresponds to an instance.
And every column in the table
refers to a variable,
often called attribute or
feature or data element.
If we look at these variables, these
columns, then we can find two main groups.
Numerical variables that
refer to a number, like for
example an age or a weight.
And categorical variables that don't
have a value that is a number,
but these are values
taken from a smaller set.
So for example, cum laude passed or
failed or true and
false are examples of
categorical variables.
If they have an order,
they're called ordinal.
If not, they are called nominal.
So these are the variables, the columns
that we see in a data mining problem.
So, to check whether you
understood what I just explained,
take a look at this data set.
And my question is, what columns refer
to ordinal categorical variables,
which to nominal categorical variables,
and which ones are numerical variables?
So please think about this for a minute.
So the answer to question is that,
there are two categorical variables.
Referring to the first two columns
where the people are a drinker or
a smoker, these are not numbers and
they are nominal because true and
false do not have some natural order.
There are two numerical variables,
the weight and
the age because they refer to a number.
There are two types of
data mining techniques,
generally referred to as supervised
learning and unsupervised learning.
In the context of supervised learning,
we have labeled data.
Labeled data means that
there is a response variable
that labels the instance.
And the goal of supervised learning is
to learn from the other variables that
are called predictor variables,
what our response variable is going to be.
So instead of response variable,
we also talk about dependent variables.
And instead of predictor variables we
also talked about independent variables.
And the goal is to explain
the dependent variable in terms of
the independent variables.
So, classification techniques,
like learning decision trees,
aim to answer such questions.
So what is the class depending on
the set of variables that we know.
If the response variable is numerical,
we typically use regression techniques.
And then the goal is to find
the function that explains
the response variable in terms
of these other variables.
So, let's take a look at this data set.
So, from every instance,
it refers to a person, and we know
whether the person was drinking or not,
smoking or not, and we know their weight.
We would like to learn
the influence of drinking and
smoking on somebody's body weight.
If you have that question, and
you think of supervised learning, what
are the response and predictor variables?
I think the answer to this
question is relatively easy.
In this particular example
the response variable is the weight.
And we would like to explain the response
variable in the predictor variables,
whether people are drinking or smoking.
Next to supervised learning we also
have unsupervised learning, and
now the data is unlabeled.
In other words,
we don't have response variables.
And the typical techniques that you
will then look at are clustering and
pattern discovery.
So you want to find homogeneous
groups of for example patients or
customers, without aiming to look
at a particular response variable.
And these are just some examples of
the many data mining
questions that you can ask.
And in the next lectures we will zoom in
to some of these questions and I will
teach you hands on knowledge to
solve these types of problems.
There are many data mining tools
available, you can see some of them here.
In my next lectures,
I will use RapidMiner to illustrate
these classical data mining techniques.
You don't have to install RapidMiner for
this course, but if you want,
you can do and you can repeat
experiments that I will show.
There are many differences between
process mining and data mining.
Let me repeat some of the things.
In what way are they common and
in what way are they different?
They both start from data, but data mining
techniques are not process-centric.
They look at isolated decisions of
the type that I've just shown to you.
Topics such as process discovery,
conformance checking,
bottleneck analysis and all the other
things that I showed in the previous
lecture, cannot be done using
traditional data mining techniques.
So you need to have process mining for
that.
End-to-end process models are crucial.
And when you want to discover end-to-end
process models, concurrency is important.
So when we
will talk about process models,
we will deal with the topic of
concurrency, because it's very important.
Process mining assumes a different type of
data than the data that we have just seen.
We assume that we can see events.
These events they have timestamps and
they refer to cases.
And that is a crucial difference with
the data the three data sets that I
showed you before.
But, process mining and
data mining can be combined to answer very
advanced questions,
so that's very important.
If you would like to learn
more about data mining and
in the next lectures we will discuss
some of the techniques in more detail,
please read chapter three
of the Process Mining book.
Thank you for watching,
and hope to see you soon.
[MUSIC]

